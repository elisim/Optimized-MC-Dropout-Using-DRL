{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras import utils\n",
    "from keras import Input, Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"\n",
    "    prepare mnist data\n",
    "    \"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "    X_train = X_train.astype(np.float32) / 255.\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "    X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "    y_train, y_test = utils.to_categorical(y_train, 10), utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    \"\"\"\n",
    "    Before calling mc-dropout, use 'set_mc_dropout_rate' \n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.mc_dropout_rate = K.variable(value=0)  # dropout before the last fully connected layer\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        x = KL.Conv2D(filters=20, kernel_size=5, strides=1)(inp)\n",
    "        x = KL.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = KL.Conv2D(filters=50, kernel_size=5, strides=1)(x)\n",
    "        x = KL.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = KL.Flatten()(x)\n",
    "        x = KL.Dense(500, activation='relu')(x)\n",
    "        x = KL.Lambda(lambda x: K.dropout(x, level=self.mc_dropout_rate))(x)  # dropout before the last fully connected layer\n",
    "        x = KL.Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        return Model(inputs=inp, outputs=x, name='lenet-mc-dropout')\n",
    "    \n",
    "    def set_mc_dropout_rate(self, new_rate):\n",
    "        K.set_value(self.mc_dropout_rate, new_rate)\n",
    "        \n",
    "    def train(self, X_train, y_train, X_test, y_test,\n",
    "              batch_size=32,\n",
    "              epochs=2,\n",
    "              optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'],\n",
    "              verbose=0):\n",
    "        \n",
    "        print(f\"Training with mc_dropout_rate = {K.eval(self.mc_dropout_rate)}.\\n\")\n",
    "        model = lenet.model\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # train the network\n",
    "        model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=verbose,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC-dropout utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_mc(net, X_test, y_test, mc_dropout_rate, sample_times=50):\n",
    "    \"\"\"\n",
    "    net: keras model with set_mc_dropout_rate function\n",
    "    \n",
    "    create mc passes.\n",
    "    avg the passes for each data.\n",
    "    compare to real y and count the number of times of an error\n",
    "    output mc error\n",
    "    \"\"\"\n",
    "    net.set_mc_dropout_rate(mc_dropout_rate)\n",
    "    model = net.model\n",
    "    batch_size = 1000\n",
    "    err = 0.\n",
    "    for batch_id in tqdm(range(X_test.shape[0] // batch_size)):\n",
    "        # take batch of data\n",
    "        x = X_test[(batch_id*batch_size):((batch_id + 1)*batch_size)]\n",
    "        # init empty predictions\n",
    "        y_ = np.zeros((sample_times, batch_size, y_test[0].shape[0])) # mc preds: T x batch x preds (T:50 x Data:1000 x labels:10)\n",
    "\n",
    "        for sample_id in range(sample_times):\n",
    "            # save predictions from a sample pass\n",
    "            y_[sample_id] = model.predict(x, batch_size) # for each pass, you have predictions for batch (1000x10)\n",
    "        \n",
    "        # average over all passes\n",
    "        mean_y = y_.mean(axis=0) # get mean of preds for each data in the passes\n",
    "        # evaluate against labels\n",
    "        y = y_test[(batch_id*batch_size):((batch_id + 1)*batch_size)]\n",
    "        # compute error\n",
    "        err += np.count_nonzero(np.not_equal(mean_y.argmax(axis=1), y.argmax(axis=1))) # count the number of wrong classifications (label is 1 and i said 2 after mc)\n",
    "\n",
    "    err = err / X_test.shape[0]\n",
    "    net.set_mc_dropout_rate(0)\n",
    "\n",
    "    return 1. - err\n",
    "\n",
    "\n",
    "def mc_dropout(net, X_test, batch_size=1000, dropout=0.5, T=100):\n",
    "    \"\"\"\n",
    "    net: keras model with set_mc_dropout_rate function\n",
    "    \n",
    "    Forward passes T times, then take the variance from all the predictions for each class.\n",
    "    the mc_dropout score for an example will be the mean of the variances for all the classes.  \n",
    "    \"\"\"\n",
    "    net.set_mc_dropout_rate(dropout)\n",
    "    model = net.model\n",
    "    repititions = []\n",
    "    for i in tqdm(range(T)):\n",
    "        pred = model.predict(X_test, batch_size)\n",
    "        repititions.append(pred)\n",
    "    net.set_mc_dropout_rate(0)\n",
    "\n",
    "    repititions = np.array(repititions) # T x btach x pred\n",
    "    mc = np.var(repititions, axis=0) # get variance from all preds for each example (output: batch x preds classes) each cell is var\n",
    "    mc = np.mean(mc, axis=-1) # mean of vars of each class (out: one dim array with batch as dim)\n",
    "    return -mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with mc_dropout_rate = 0.5.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 0.1535 - acc: 0.9530 - val_loss: 0.0744 - val_acc: 0.9761\n",
      "Epoch 2/2\n",
      " - 16s - loss: 0.0675 - acc: 0.9802 - val_loss: 0.0542 - val_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = prepare_data()\n",
    "\n",
    "# prepare the model\n",
    "lenet = LeNet(\n",
    "    input_shape=X_train.shape[1:],\n",
    "    num_classes=10,\n",
    ")\n",
    "\n",
    "# train\n",
    "lenet.set_mc_dropout_rate(0.5)\n",
    "lenet.train(X_train, y_train, X_test, y_test, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.9881\n"
     ]
    }
   ],
   "source": [
    "acc = evalute_mc(lenet, X_test, y_test, mc_dropout_rate=0.5)\n",
    "print(\"acc = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf = np.random.rand(*X_test[:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1617.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1566.72it/s]\n"
     ]
    }
   ],
   "source": [
    "ok_socre = mc_dropout(lenet, X_test[:1])\n",
    "wtf_score = mc_dropout(lenet, wtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.2906408e-12]\n",
      "[-0.02490894]\n"
     ]
    }
   ],
   "source": [
    "print(ok_socre)\n",
    "print(wtf_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}