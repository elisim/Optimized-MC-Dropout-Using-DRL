{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras import utils\n",
    "from keras import Input, Model\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"\n",
    "    prepare mnist data\n",
    "    \"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "    X_train = X_train.astype(np.float32) / 255.\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "    X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "    y_train, y_test = utils.to_categorical(y_train, 10), utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    \"\"\"\n",
    "    Before calling mc-dropout, use 'set_mc_dropout_rate' \n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.mc_dropout_rate = K.variable(value=0)  # dropout before the last fully connected layer\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        x = KL.Conv2D(filters=20, kernel_size=5, strides=1)(inp)\n",
    "        x = KL.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = KL.Conv2D(filters=50, kernel_size=5, strides=1)(x)\n",
    "        x = KL.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = KL.Flatten()(x)\n",
    "        x = KL.Dense(500, activation='relu')(x)\n",
    "        x = KL.Lambda(lambda x: K.dropout(x, level=self.mc_dropout_rate))(x)  # dropout before the last fully connected layer\n",
    "        x = KL.Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        return Model(inputs=inp, outputs=x, name='lenet-mc-dropout')\n",
    "    \n",
    "    def set_mc_dropout_rate(self, new_rate):\n",
    "        K.set_value(self.mc_dropout_rate, new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_mc(net, X_test, y_test, mc_dropout_rate, sample_times=50):\n",
    "    net.set_mc_dropout_rate(mc_dropout_rate)\n",
    "    model = net.model\n",
    "    batch_size = 1000\n",
    "    err = 0.\n",
    "    for batch_id in tqdm(range(X_test.shape[0] // batch_size)):\n",
    "        # take batch of data\n",
    "        x = X_test[(batch_id*batch_size):((batch_id + 1)*batch_size)]\n",
    "        # init empty predictions\n",
    "        y_ = np.zeros((sample_times, batch_size, y_test[0].shape[0]))\n",
    "\n",
    "        for sample_id in range(sample_times):\n",
    "            # save predictions from a sample pass\n",
    "            y_[sample_id] = model.predict(x, batch_size)\n",
    "\n",
    "        # average over all passes\n",
    "        mean_y = y_.mean(axis=0)\n",
    "        # evaluate against labels\n",
    "        y = y_test[batch_size * batch_id: (batch_id + 1) * batch_size]\n",
    "        # compute error\n",
    "        err += np.count_nonzero(np.not_equal(mean_y.argmax(axis=1), y.argmax(axis=1)))\n",
    "\n",
    "    err = err / X_test.shape[0]\n",
    "\n",
    "    return 1. - err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout(net, X_test, batch_size=1000, dropout=0.5, T=100):\n",
    "    net.set_mc_dropout_rate(dropout)\n",
    "    model = net.model\n",
    "    repititions = []\n",
    "    for i in tqdm(range(T)):\n",
    "        pred = model.predict(X_test, batch_size)\n",
    "        repititions.append(pred)\n",
    "    net.set_mc_dropout_rate(0)\n",
    "\n",
    "    repititions = np.array(repititions)\n",
    "    mc = np.var(repititions, 0)\n",
    "    mc = np.mean(mc, -1)\n",
    "    return -mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.1198 - acc: 0.9634 - val_loss: 0.0621 - val_acc: 0.9800\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0495 - acc: 0.9848 - val_loss: 0.0391 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e6ecf9fc88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = prepare_data()\n",
    "\n",
    "# prepare the model\n",
    "lenet = LeNet(\n",
    "    input_shape=X_train.shape[1:],\n",
    "    num_classes=10,\n",
    ")\n",
    "\n",
    "\n",
    "#### train\n",
    "model = lenet.model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# train the network\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.9872\n"
     ]
    }
   ],
   "source": [
    "acc = evalute_mc(lenet, X_test, y_test, mc_dropout_rate=0.5)\n",
    "print(\"acc = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf = np.random.rand(*X_test[:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1496.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1671.12it/s]\n"
     ]
    }
   ],
   "source": [
    "ok_socre = mc_dropout(lenet, X_test[:1])\n",
    "wtf_score = mc_dropout(lenet, wtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.2645273e-10]\n",
      "[-0.01651107]\n"
     ]
    }
   ],
   "source": [
    "print(ok_socre)\n",
    "print(wtf_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
